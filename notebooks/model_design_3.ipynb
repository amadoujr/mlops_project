{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    training_set,\n",
    "    pipeline,\n",
    "    mlflow_run_tags=None,\n",
    "    mlflow_run_parameters=None,\n",
    "    mlflow_run_description=None,\n",
    "    validation_set=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a sentiment analysis model, print the evaluation result and store everything to MLFlow.\n",
    "\n",
    "    @param: training_set: pandas dataframe containing the input training set\n",
    "    @param: pipeline: scikit-learn pipeline that will be applied to the input data\n",
    "    @param: mlflow_run_tags: dict of tags that will be stored in the MLFlow run\n",
    "    @param: mlflow_run_parameters: dict of parameters that will be stored in the MLFlow run\n",
    "    @param: mlflow_run_description: textual description of the run\n",
    "    @param: validation_set: if provided, used to evaluate the model and log result in MLFlow\n",
    "    @return: the trained pipeline\n",
    "    \"\"\"\n",
    "    # S√©paration des features et des labels\n",
    "    X_train,y_train = training_set[0], training_set[1]\n",
    "    if validation_set is not None:\n",
    "        X_val,y_val  = validation_set[0],validation_set[1]\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.sklearn.autolog(log_datasets=False)\n",
    "        # Ajout de tags\n",
    "        if mlflow_run_tags:\n",
    "            for tag, value in mlflow_run_tags.items():\n",
    "                mlflow.set_tag(tag, value)        \n",
    "        if mlflow_run_parameters:\n",
    "            for param, value in mlflow_run_parameters.items():\n",
    "                mlflow.log_param(param, value)\n",
    "        if mlflow_run_description:\n",
    "            mlflow.set_tag(\"Description\", mlflow_run_description)\n",
    "\n",
    "        # Entra√Ænement le mod√®le\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        # √âvalue le mod√®le si le jeu de validation est fourni\n",
    "        if validation_set is not None:\n",
    "            y_pred = pipeline.predict(X_val)\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "            precision = precision_score(y_val, y_pred)\n",
    "            recall = recall_score(y_val, y_pred)\n",
    "            \n",
    "            mlflow.log_metric(\"accuracy_val\", accuracy)\n",
    "            mlflow.log_metric(\"precision_val\", precision)\n",
    "            mlflow.log_metric(\"recall_val\", recall)\n",
    "        mlflow.sklearn.log_model(pipeline, \"model_pipeline\")\n",
    "\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "train_data = pd.read_csv(\"../archive/train.csv\")\n",
    "valid_data = pd.read_csv(\"../archive/valid.csv\")\n",
    "test_data  = pd.read_csv(\"../archive/test.csv\")\n",
    "\n",
    "train_reviews = train_data.review.values\n",
    "valid_review  = valid_data.review.values\n",
    "\n",
    "y_val  = valid_data['polarity']\n",
    "y_train = train_data['polarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2024/11/12 17:30:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/12 17:30:11 INFO mlflow.tracking._tracking_service.client: üèÉ View run secretive-wasp-751 at: http://127.0.0.1:5000/#/experiments/999691338119668531/runs/c7b822185b154413a28079b9c6fc94e1.\n",
      "2024/11/12 17:30:11 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/999691338119668531.\n",
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2024/11/12 17:32:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/12 17:32:35 INFO mlflow.tracking._tracking_service.client: üèÉ View run bedecked-owl-858 at: http://127.0.0.1:5000/#/experiments/999691338119668531/runs/384aee30ee6644c1a9284c352c0d0756.\n",
      "2024/11/12 17:32:35 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/999691338119668531.\n",
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2024/11/12 17:35:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/12 17:35:04 INFO mlflow.tracking._tracking_service.client: üèÉ View run adorable-robin-205 at: http://127.0.0.1:5000/#/experiments/999691338119668531/runs/942cdd35b96e428fa4cb4ca743d2a79f.\n",
      "2024/11/12 17:35:04 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/999691338119668531.\n",
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2024/11/12 17:37:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/12 17:37:12 INFO mlflow.tracking._tracking_service.client: üèÉ View run adorable-robin-129 at: http://127.0.0.1:5000/#/experiments/999691338119668531/runs/8fd30358b7d344149d54eb66edd8c217.\n",
      "2024/11/12 17:37:12 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/999691338119668531.\n",
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2024/11/12 17:39:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/12 17:39:15 INFO mlflow.tracking._tracking_service.client: üèÉ View run salty-sheep-730 at: http://127.0.0.1:5000/#/experiments/999691338119668531/runs/677b1349698a44178fab7bbec05eeed3.\n",
      "2024/11/12 17:39:15 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/999691338119668531.\n",
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2024/11/12 17:41:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/12 17:41:46 INFO mlflow.tracking._tracking_service.client: üèÉ View run salty-hog-667 at: http://127.0.0.1:5000/#/experiments/999691338119668531/runs/8e2ac2fa670741a2a0d330f29db3538e.\n",
      "2024/11/12 17:41:46 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/999691338119668531.\n",
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2024/11/12 17:44:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/12 17:44:09 INFO mlflow.tracking._tracking_service.client: üèÉ View run likeable-fish-61 at: http://127.0.0.1:5000/#/experiments/999691338119668531/runs/00f98f67dab0448a86067ff2facd5d47.\n",
      "2024/11/12 17:44:09 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/999691338119668531.\n",
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2024/11/12 17:46:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/12 17:46:26 INFO mlflow.tracking._tracking_service.client: üèÉ View run capable-yak-471 at: http://127.0.0.1:5000/#/experiments/999691338119668531/runs/99eb40bbf7104e4fa5227c775d19783e.\n",
      "2024/11/12 17:46:26 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/999691338119668531.\n",
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2024/11/12 21:19:49 INFO mlflow.tracking._tracking_service.client: üèÉ View run monumental-croc-669 at: http://127.0.0.1:5000/#/experiments/999691338119668531/runs/dfd648dbdbee40539b65dc8963fdaa1f.\n",
      "2024/11/12 21:19:49 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/999691338119668531.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m estimators \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_processing\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(fr_stop))),(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlrg\u001b[39m\u001b[38;5;124m'\u001b[39m, lg)]\n\u001b[1;32m     19\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(estimators)\n\u001b[0;32m---> 20\u001b[0m pipe_res  \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_reviews\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_review\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 37\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(training_set, pipeline, mlflow_run_tags, mlflow_run_parameters, mlflow_run_description, validation_set)\u001b[0m\n\u001b[1;32m     34\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mset_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m\"\u001b[39m, mlflow_run_description)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Entra√Ænement le mod√®le\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# √âvaluer le mod√®le si le jeu de validation est fourni\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:580\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m     patch_function\u001b[38;5;241m.\u001b[39mcall(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 580\u001b[0m     \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m session\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m try_log_autologging_event(\n\u001b[1;32m    585\u001b[0m     AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_patch_function_success,\n\u001b[1;32m    586\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     kwargs,\n\u001b[1;32m    591\u001b[0m )\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:249\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001b[0;34m(original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     managed_run \u001b[38;5;241m=\u001b[39m create_managed_run()\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 249\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m managed_run:\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/sklearn/__init__.py:1654\u001b[0m, in \u001b[0;36m_autolog.<locals>.patched_fit\u001b[0;34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mshould_log():\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;66;03m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m     \u001b[38;5;66;03m# so we need temporarily disable the post_training_metrics patching.\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _AUTOLOGGING_METRICS_MANAGER\u001b[38;5;241m.\u001b[39mdisable_log_post_training_metrics():\n\u001b[0;32m-> 1654\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfit_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_log_post_training_metrics:\n\u001b[1;32m   1656\u001b[0m         _AUTOLOGGING_METRICS_MANAGER\u001b[38;5;241m.\u001b[39mregister_model(\n\u001b[1;32m   1657\u001b[0m             \u001b[38;5;28mself\u001b[39m, mlflow\u001b[38;5;241m.\u001b[39mactive_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m   1658\u001b[0m         )\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/sklearn/__init__.py:1430\u001b[0m, in \u001b[0;36m_autolog.<locals>.fit_mlflow\u001b[0;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m params_logging_future \u001b[38;5;241m=\u001b[39m autologging_client\u001b[38;5;241m.\u001b[39mflush(synchronous\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1429\u001b[0m fit_output \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1430\u001b[0m \u001b[43m_log_posttraining_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautologging_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1431\u001b[0m autologging_client\u001b[38;5;241m.\u001b[39mflush(synchronous\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1432\u001b[0m params_logging_future\u001b[38;5;241m.\u001b[39mawait_completion()\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/sklearn/__init__.py:1528\u001b[0m, in \u001b[0;36m_autolog.<locals>._log_posttraining_metadata\u001b[0;34m(autologging_client, estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m infer_signature(input_example, model_output)\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;66;03m# log common metrics and artifacts for estimators (classifier, regressor)\u001b[39;00m\n\u001b[0;32m-> 1528\u001b[0m logged_metrics \u001b[38;5;241m=\u001b[39m \u001b[43m_log_estimator_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautologging_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautologging_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_TRAINING_PREFIX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logged_metrics:\n\u001b[1;32m   1539\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining metrics will not be recorded because training labels were not specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m To automatically record training metrics, provide training labels as inputs to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the model training function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1543\u001b[0m     )\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/sklearn/utils.py:643\u001b[0m, in \u001b[0;36m_log_estimator_content\u001b[0;34m(autologging_client, estimator, run_id, prefix, X, y_true, sample_weight, pos_label)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_log_estimator_content\u001b[39m(\n\u001b[1;32m    611\u001b[0m     autologging_client,\n\u001b[1;32m    612\u001b[0m     estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m     pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    619\u001b[0m ):\n\u001b[1;32m    620\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m    Logs content for the given estimator, which includes metrics and artifacts that might be\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    tailored to the estimator's type (e.g., regression vs classification). Training labels\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m        A dict of the computed metrics.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 643\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43m_log_specialized_estimator_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautologging_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautologging_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfitted_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m y_true \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m             \u001b[38;5;66;03m# Use the sample weight only if it is present in the score args\u001b[39;00m\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/sklearn/utils.py:523\u001b[0m, in \u001b[0;36m_log_specialized_estimator_content\u001b[0;34m(autologging_client, fitted_estimator, run_id, prefix, X, y_true, sample_weight, pos_label)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sklearn\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mis_classifier(fitted_estimator):\n\u001b[0;32m--> 523\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[43m_get_classifier_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfitted_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m sklearn\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mis_regressor(fitted_estimator):\n\u001b[1;32m    527\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m _get_regressor_metrics(fitted_estimator, prefix, X, y_true, sample_weight)\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/sklearn/utils.py:205\u001b[0m, in \u001b[0;36m_get_classifier_metrics\u001b[0;34m(fitted_estimator, prefix, X, y_true, sample_weight, pos_label)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m    204\u001b[0m average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 205\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mfitted_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m classifier_metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    208\u001b[0m     _SklearnMetric(\n\u001b[1;32m    209\u001b[0m         name\u001b[38;5;241m=\u001b[39mprefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m     ),\n\u001b[1;32m    251\u001b[0m ]\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fitted_estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:580\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m     patch_function\u001b[38;5;241m.\u001b[39mcall(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 580\u001b[0m     \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m session\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m try_log_autologging_event(\n\u001b[1;32m    585\u001b[0m     AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_patch_function_success,\n\u001b[1;32m    586\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     kwargs,\n\u001b[1;32m    591\u001b[0m )\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/sklearn/__init__.py:1712\u001b[0m, in \u001b[0;36m_autolog.<locals>.patched_predict\u001b[0;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict_result\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:561\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:496\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    489\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    490\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m         og_kwargs,\n\u001b[1;32m    495\u001b[0m     )\n\u001b[0;32m--> 496\u001b[0m     original_fn_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    499\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    500\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m         og_kwargs,\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:558\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[1;32m    555\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    556\u001b[0m     reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m ):\n\u001b[0;32m--> 558\u001b[0m     original_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/pipeline.py:600\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:2115\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   2098\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[1;32m   2099\u001b[0m \n\u001b[1;32m   2100\u001b[0m \u001b[38;5;124;03mUses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2113\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2115\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mtransform(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1417\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_vocabulary()\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[0;32m-> 1417\u001b[0m _, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1419\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "mlflow.set_experiment(\"MLflow log_reg experience\")\n",
    "\n",
    "MAX_ITER = 500\n",
    "scores = []\n",
    "parameters = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1','l2']}\n",
    "for c in parameters.get('C'):\n",
    "    for pen in parameters.get('penalty'):\n",
    "        lg = LogisticRegression(C=c, penalty=pen, max_iter=MAX_ITER, solver='liblinear', random_state=42)\n",
    "        estimators = [('pre_processing', TfidfVectorizer(stop_words=list(fr_stop))),('lrg', lg)]\n",
    "        pipe = Pipeline(estimators)\n",
    "        pipe_res  = build_model((train_reviews,y_train),pipe,validation_set=(valid_review,y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def build_optimized_model(\n",
    "    training_set,\n",
    "    validation_set,\n",
    "    pipeline_template,\n",
    "    search_space,\n",
    "    mlflow_run_tags=None,\n",
    "    mlflow_run_description=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Build and optimize a machine learning model, logging all results to MLFlow.\n",
    "\n",
    "    Parameters:\n",
    "    - training_set: tuple (X_train, y_train)\n",
    "    - validation_set: tuple (X_val, y_val)\n",
    "    - pipeline_template: a scikit-learn pipeline template\n",
    "    - search_space: hyperopt search space\n",
    "    - mlflow_run_tags: dict of tags for MLFlow\n",
    "    - mlflow_run_description: textual description for the MLFlow run\n",
    "\n",
    "    Returns:\n",
    "    - The trained and optimized pipeline.\n",
    "    \"\"\"\n",
    "    X_train, y_train = training_set\n",
    "    X_val, y_val = validation_set\n",
    "\n",
    "    def objective(params):\n",
    "        pipeline = pipeline_template.set_params(**params)        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        # Evaluate on the validation set\n",
    "        y_pred = pipeline.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        return {'loss': 1 - accuracy, 'status': STATUS_OK}\n",
    "\n",
    "    # Use of hyperopt to find the best parameters\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=5, \n",
    "        trials=trials\n",
    "    )\n",
    "    print(best_params)\n",
    "    # Train the final model with the best parameters\n",
    "    best_params_with_prefix = {f\"lrg__{key}\": value for key, value in best_params.items()}\n",
    "    optimized_pipeline = pipeline_template.set_params(**best_params_with_prefix)\n",
    "    optimized_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Log everything to MLFlow\n",
    "    with mlflow.start_run() as run:\n",
    "        if mlflow_run_tags:\n",
    "            for tag, value in mlflow_run_tags.items():\n",
    "                mlflow.set_tag(tag, value)\n",
    "        if mlflow_run_description:\n",
    "            mlflow.set_tag(\"Description\", mlflow_run_description)\n",
    "\n",
    "        # Log the best hyperparameters\n",
    "        mlflow.log_params(best_params)\n",
    "        \n",
    "        # Evaluate on the validation set\n",
    "        y_pred = optimized_pipeline.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"accuracy_val\", accuracy)\n",
    "\n",
    "        # Log the final model\n",
    "        mlflow.sklearn.log_model(optimized_pipeline, \"optimized_pipeline\")\n",
    "\n",
    "    return optimized_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [03:03<01:59, 59.56s/trial, best loss: 0.12490000000000001]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amadouu/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [05:03<00:00, 60.62s/trial, best loss: 0.12490000000000001]\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 1 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m valid_review, valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolarity\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m pipeline_template \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     11\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_processing\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(fr_stop))),\n\u001b[1;32m     12\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlrg\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)),\n\u001b[1;32m     13\u001b[0m ])\n\u001b[0;32m---> 15\u001b[0m optimized_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_optimized_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlflow_run_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhyperopt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlflow_run_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHyperparameter optimization with hyperopt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 49\u001b[0m, in \u001b[0;36mbuild_optimized_model\u001b[0;34m(training_set, validation_set, pipeline_template, search_space, mlflow_run_tags, mlflow_run_description)\u001b[0m\n\u001b[1;32m     47\u001b[0m best_params_with_prefix \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlrg__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m best_params\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     48\u001b[0m optimized_pipeline \u001b[38;5;241m=\u001b[39m pipeline_template\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params_with_prefix)\n\u001b[0;32m---> 49\u001b[0m \u001b[43moptimized_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Log everything to MLFlow\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run() \u001b[38;5;28;01mas\u001b[39;00m run:\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/base.py:1466\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1461\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1462\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1463\u001b[0m )\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1466\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/base.py:666\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    659\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 666\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/M2_ML/NLP/env_nlp/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 1 instead."
     ]
    }
   ],
   "source": [
    "### Search space\n",
    "search_space = {\n",
    "    'lrg__C': hp.loguniform('C', 0.01, 100),  # log scale for C (e.g., 0.01 to 100)\n",
    "    'lrg__penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "}\n",
    "\n",
    "X_train, y_train = train_reviews, train_data['polarity']\n",
    "X_val, y_val = valid_review, valid_data['polarity']\n",
    "\n",
    "pipeline_template = Pipeline([\n",
    "    ('pre_processing', TfidfVectorizer(stop_words=list(fr_stop))),\n",
    "    ('lrg', LogisticRegression(solver='liblinear', random_state=42)),\n",
    "])\n",
    "\n",
    "optimized_model = build_optimized_model(\n",
    "    training_set=(X_train, y_train),\n",
    "    validation_set=(X_val, y_val),\n",
    "    pipeline_template=pipeline_template,\n",
    "    search_space=search_space,\n",
    "    mlflow_run_tags={\"optimization\": \"hyperopt\"},\n",
    "    mlflow_run_description=\"Hyperparameter optimization with hyperopt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "env_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
